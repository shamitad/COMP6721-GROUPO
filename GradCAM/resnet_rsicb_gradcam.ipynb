{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqprv4Om5qtT"
      },
      "source": [
        "# Resnet on RSICB dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jtTobBgo8g9",
        "outputId": "a0213c98-5cbe-4ae6-f025-55fc2dff1c6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3GKjW4ypLYS",
        "outputId": "0352ce5e-7cc1-4088-e5e3-262af2844fd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extraction complete. Check the folder: AI datasets\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to your zip file\n",
        "zip_path = '/content/drive/MyDrive/AI project dataset.zip'\n",
        "extract_dir = 'AI datasets'  # Folder where all extracted folders will be stored\n",
        "\n",
        "# Create a main extraction directory\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# Extract each main folder separately\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    for file in zip_ref.namelist():\n",
        "        # Extract files while preserving folder structure\n",
        "        zip_ref.extract(file, extract_dir)\n",
        "\n",
        "print(\"Extraction complete. Check the folder:\", extract_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAr5uB2ppvTh"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7H2uxJjp7pf",
        "outputId": "78838ed6-839d-4c93-f5a2-c6ba6ba801c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjXy_i0gqBx7"
      },
      "outputs": [],
      "source": [
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIHPgjccqKPf"
      },
      "outputs": [],
      "source": [
        "dataset = torchvision.datasets.ImageFolder(root='/content/AI datasets/RSI-CB/RSI-CB256/', transform=data_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NrstXExqP3f"
      },
      "outputs": [],
      "source": [
        "train_size = int(0.7 * len(dataset))\n",
        "valid_size = int(0.2 * len(dataset))\n",
        "test_size = len(dataset) - train_size - valid_size\n",
        "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size, test_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b2U1YkEqQFS",
        "outputId": "5e95050b-640d-47e6-d9e7-5c26b79124de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with batch size: 64, learning rate: 0.001, and epochs: 40\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "num_epochs = 40\n",
        "\n",
        "# Print the configuration\n",
        "print(f\"Training with batch size: {batch_size}, learning rate: {learning_rate}, and epochs: {num_epochs}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljWAx8bXqQIq"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_vSgARqqQLe",
        "outputId": "32c049a9-e026-4f5d-b8c2-9c73c6a386b5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = models.resnet18(pretrained=False)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs,5)\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTFfAqVPqcAH"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXAuEvX3qcDm"
      },
      "outputs": [],
      "source": [
        "loss_during_epoch = []\n",
        "accuracy_during_epoch = []\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GradCAM:\n",
        "    def __init__(self, model, target_layer):\n",
        "        self.model = model\n",
        "        self.target_layer = target_layer\n",
        "        self.gradients = None\n",
        "        self.activations = None\n",
        "        self.target_layer.register_forward_hook(self.forward_hook)\n",
        "        self.target_layer.register_backward_hook(self.backward_hook)\n",
        "\n",
        "    def forward_hook(self, module, input, output):\n",
        "        self.activations = output\n",
        "\n",
        "    def backward_hook(self, module, grad_input, grad_output):\n",
        "        self.gradients = grad_output[0]\n",
        "\n",
        "    def generate_cam(self, input_tensor, target_class=None):\n",
        "        output = self.model(input_tensor)\n",
        "\n",
        "        if target_class is None:\n",
        "            target_class = torch.argmax(output, dim=1)\n",
        "\n",
        "        self.model.zero_grad()\n",
        "        output[:, target_class].backward(retain_graph=True)\n",
        "\n",
        "        gradients = self.gradients[0].cpu().data.numpy()\n",
        "        activations = self.activations[0].cpu().data.numpy()\n",
        "\n",
        "        weights = np.mean(gradients, axis=(1, 2))\n",
        "        cam = np.zeros(activations.shape[1:], dtype=np.float32)\n",
        "\n",
        "        for i, w in enumerate(weights):\n",
        "            cam += w * activations[i]\n",
        "\n",
        "        cam = np.maximum(cam, 0)\n",
        "        cam = cam / np.max(cam)\n",
        "        return cam\n",
        "\n",
        "def visualize_gradcam(cam, original_image, alpha=0.5):\n",
        "    cam = cv2.resize(cam, (original_image.shape[1], original_image.shape[0]))\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
        "    heatmap = np.float32(heatmap) / 255\n",
        "    overlay = heatmap + np.float32(original_image / 255)\n",
        "    overlay = overlay / np.max(overlay)\n",
        "    return np.uint8(255 * overlay)\n"
      ],
      "metadata": {
        "id": "mBcBxjTRBIMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patience = 5\n",
        "best_valid_loss = float('inf')\n",
        "epochs_no_improve = 0\n",
        "early_stopping = False\n",
        "\n",
        "train_loss_list = []\n",
        "train_accuracy_list = []\n",
        "valid_loss_list = []\n",
        "valid_accuracy_list = []\n",
        "\n",
        "target_layer = model.features[-1]\n",
        "gradcam = GradCAM(model, target_layer)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "        total_predictions += labels.size(0)\n",
        "\n",
        "    model.eval()\n",
        "    valid_loss = 0.0\n",
        "    valid_correct_predictions = 0\n",
        "    valid_total_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for valid_inputs, valid_labels in valid_loader:\n",
        "            valid_inputs, valid_labels = valid_inputs.to(device), valid_labels.to(device)\n",
        "            valid_outputs = model(valid_inputs)\n",
        "            valid_loss += criterion(valid_outputs, valid_labels).item()\n",
        "\n",
        "            _, valid_predicted = torch.max(valid_outputs, 1)\n",
        "            valid_correct_predictions += (valid_predicted == valid_labels).sum().item()\n",
        "            valid_total_predictions += valid_labels.size(0)\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_accuracy = correct_predictions / total_predictions\n",
        "    valid_loss = valid_loss / len(valid_loader)\n",
        "    valid_accuracy = valid_correct_predictions / valid_total_predictions\n",
        "\n",
        "    train_loss_list.append(train_loss)\n",
        "    train_accuracy_list.append(train_accuracy)\n",
        "    valid_loss_list.append(valid_loss)\n",
        "    valid_accuracy_list.append(valid_accuracy)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {train_loss}, Accuracy: {train_accuracy * 100:.2f}%, \"\n",
        "          f\"Validation Loss: {valid_loss}, Validation Accuracy: {valid_accuracy * 100:.2f}%, \"\n",
        "          f\"Running time: {elapsed_time}\")\n",
        "\n",
        "    sample_inputs, sample_labels = next(iter(valid_loader))\n",
        "    sample_inputs = sample_inputs.to(device)\n",
        "    original_image = sample_inputs[0].permute(1, 2, 0).cpu().numpy()  # Convert to HWC format\n",
        "\n",
        "    cam = gradcam.generate_cam(sample_inputs[0].unsqueeze(0))  # Generate Grad-CAM\n",
        "    overlay_image = visualize_gradcam(cam, original_image)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title(\"Original Image\")\n",
        "    plt.imshow(original_image)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title(\"Grad-CAM Overlay\")\n",
        "    plt.imshow(overlay_image)\n",
        "    plt.show()\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        epochs_no_improve = 0\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if epochs_no_improve == patience:\n",
        "            print(\"Early stopping!\")\n",
        "            early_stopping = True\n",
        "            break\n",
        "\n",
        "if early_stopping:\n",
        "    print(\"Training stopped due to early stopping.\")\n",
        "else:\n",
        "    print(\"Training completed all epochs.\")\n"
      ],
      "metadata": {
        "id": "QZA8HzKwBIU1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}